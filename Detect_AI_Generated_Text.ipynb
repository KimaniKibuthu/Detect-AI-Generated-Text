{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VATXkTFi-2eO"
      },
      "source": [
        "# Detect AI Generated Text\n",
        "In this challenge, the goal is to determine whether a piece of text is AI generated or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbGgQynG_FYs"
      },
      "source": [
        "# Import the necessary libraries\n",
        "Here, we import the libraries necessary for the challenge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-kDWMem-q_j",
        "outputId": "2d95515c-6c67-4767-baa1-885afd63d636"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\Spectra\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Spectra\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Spectra\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Spectra\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package words to\n",
            "[nltk_data]     C:\\Users\\Spectra\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\Spectra\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Libraries\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# NLTK\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.metrics import classification_report, roc_auc_score, make_scorer, recall_score\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from hyperopt import fmin, tpe, hp, Trials\n",
        "\n",
        "# Download NLTK Resources\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn1dQHJV_bm7"
      },
      "source": [
        "# Obtain data\n",
        "Here, we obtain the data to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NEx70HlMSsxn"
      },
      "outputs": [],
      "source": [
        "# get training data\n",
        "final_augmented_train = pd.read_csv(\"data/final_augmented_data.csv\")\n",
        "test_df = pd.read_csv(\"data/test_essays.csv\")\n",
        "new_data_one = pd.read_csv(\"data/train_drcat_01.csv\")\n",
        "new_data_two = pd.read_csv(\"data/train_drcat_02.csv\")\n",
        "new_data_three = pd.read_csv(\"data/train_drcat_03.csv\")\n",
        "new_data_four = pd.read_csv(\"data/train_drcat_04.csv\")\n",
        "augmented_test = pd.read_csv(\"data/archive (2).zip (Unzipped Files)/final_test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7QuAHVphpfD"
      },
      "source": [
        "**Get train data ready**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IsNX9pPhhxoh"
      },
      "outputs": [],
      "source": [
        "# Rename Columns\n",
        "new_data_four.rename(columns={'label': 'generated'}, inplace=True)\n",
        "new_data_two.rename(columns={'label': 'generated'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hReP_dZng6D7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iiwvYv8Biolo",
        "outputId": "243416ba-cc75-4cc4-a5e8-e10bd037f79b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dear Mr. Senator, I have decided to express my...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Limiting car usage is advantageous for multip...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Limiting car usage is beneficial for a number...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"The day that mankind realizes that their crea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dear me. Senator, I am fed up with the elector...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  generated\n",
              "0  Dear Mr. Senator, I have decided to express my...          0\n",
              "1   Limiting car usage is advantageous for multip...          1\n",
              "2   Limiting car usage is beneficial for a number...          1\n",
              "3  \"The day that mankind realizes that their crea...          0\n",
              "4  Dear me. Senator, I am fed up with the elector...          0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Concat the data\n",
        "concat_train_df = pd.concat([final_augmented_train,\n",
        "                             new_data_two[[\"text\", \"generated\"]],\n",
        "                             new_data_four[[\"text\", \"generated\"]]], axis=0)\n",
        "\n",
        "concat_train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BO4ZvMnHjE3T",
        "outputId": "1ca3362e-ab9a-4448-eb34-3c8a81f2439a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dear Mr. Senator, I have decided to express my...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Limiting car usage is advantageous for multip...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Limiting car usage is beneficial for a number...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"The day that mankind realizes that their crea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dear me. Senator, I am fed up with the elector...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44131</th>\n",
              "      <td>Looking for some fun activities to do at the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44142</th>\n",
              "      <td>The school administration has recently announ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44144</th>\n",
              "      <td>\\nSeeking advice from more than one person whe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44160</th>\n",
              "      <td>While the Facial Action Coding System technolo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44197</th>\n",
              "      <td>The Seagoing Cowboys program is an amazing opp...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>137988 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  generated\n",
              "0      Dear Mr. Senator, I have decided to express my...          0\n",
              "1       Limiting car usage is advantageous for multip...          1\n",
              "2       Limiting car usage is beneficial for a number...          1\n",
              "3      \"The day that mankind realizes that their crea...          0\n",
              "4      Dear me. Senator, I am fed up with the elector...          0\n",
              "...                                                  ...        ...\n",
              "44131   Looking for some fun activities to do at the ...          1\n",
              "44142   The school administration has recently announ...          1\n",
              "44144  \\nSeeking advice from more than one person whe...          1\n",
              "44160  While the Facial Action Coding System technolo...          1\n",
              "44197  The Seagoing Cowboys program is an amazing opp...          1\n",
              "\n",
              "[137988 rows x 2 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop duplicates\n",
        "concat_train_df.drop_duplicates(subset=[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "izgVo6QejaqH"
      },
      "outputs": [],
      "source": [
        "sampled_train_df, _ = train_test_split(concat_train_df,\n",
        "                                       test_size=(len(concat_train_df) - 100000) / len(concat_train_df),\n",
        "                                       stratify=concat_train_df[\"generated\"],\n",
        "                                       random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkXd_TfFkMOx"
      },
      "source": [
        "**Sample Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rkvkOlH0kPEY"
      },
      "outputs": [],
      "source": [
        "# Rename columns\n",
        "new_data_three.rename(columns={'label': 'generated'}, inplace=True)\n",
        "new_data_one.rename(columns={'label': 'generated'}, inplace=True)\n",
        "augmented_test.rename(columns={'label': 'generated'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8uZk5hAKkYsu",
        "outputId": "e69a81d8-8521-4a5d-d526-a8829be25b80"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Face on Mars is nothing but a natural occu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Students have a higher chance of catching a vi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Driverless cars have good and bad things that ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Some people might think that traveling in a gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How many of us students want to be forced to d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42201</th>\n",
              "      <td>\"Oh man I didn't make the soccer team!\", yelle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42202</th>\n",
              "      <td>I believe that using this technology could be ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42203</th>\n",
              "      <td>The Face on Mars is a fascinating phenomenon t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42204</th>\n",
              "      <td>Texting &amp; Driving\\n\\nUsing your phone while dr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42205</th>\n",
              "      <td>Dear Principal,\\n\\nI have been really good thi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>162052 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  generated\n",
              "0      The Face on Mars is nothing but a natural occu...          0\n",
              "1      Students have a higher chance of catching a vi...          0\n",
              "2      Driverless cars have good and bad things that ...          0\n",
              "3      Some people might think that traveling in a gr...          1\n",
              "4      How many of us students want to be forced to d...          0\n",
              "...                                                  ...        ...\n",
              "42201  \"Oh man I didn't make the soccer team!\", yelle...          0\n",
              "42202  I believe that using this technology could be ...          0\n",
              "42203  The Face on Mars is a fascinating phenomenon t...          1\n",
              "42204  Texting & Driving\\n\\nUsing your phone while dr...          0\n",
              "42205  Dear Principal,\\n\\nI have been really good thi...          0\n",
              "\n",
              "[162052 rows x 2 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Concat the data\n",
        "concat_eval_df = pd.concat([augmented_test,\n",
        "                             new_data_one[[\"text\", \"generated\"]],\n",
        "                             new_data_three[[\"text\", \"generated\"]]], axis=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-Tz9QSktkd-j",
        "outputId": "8e19e1b4-40b2-4f65-93b6-3132ee0d852a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Face on Mars is nothing but a natural occu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Students have a higher chance of catching a vi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Driverless cars have good and bad things that ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Some people might think that traveling in a gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How many of us students want to be forced to d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42190</th>\n",
              "      <td>I think our principal's idea of making us do e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42191</th>\n",
              "      <td>I think it's a good idea for schools to have o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42196</th>\n",
              "      <td>Students often debate whether inactivity or s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42199</th>\n",
              "      <td>Advantages of Limiting Car Usage\\n\\nLimiting c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42203</th>\n",
              "      <td>The Face on Mars is a fascinating phenomenon t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>127344 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  generated\n",
              "0      The Face on Mars is nothing but a natural occu...          0\n",
              "1      Students have a higher chance of catching a vi...          0\n",
              "2      Driverless cars have good and bad things that ...          0\n",
              "3      Some people might think that traveling in a gr...          1\n",
              "4      How many of us students want to be forced to d...          0\n",
              "...                                                  ...        ...\n",
              "42190  I think our principal's idea of making us do e...          1\n",
              "42191  I think it's a good idea for schools to have o...          1\n",
              "42196   Students often debate whether inactivity or s...          1\n",
              "42199  Advantages of Limiting Car Usage\\n\\nLimiting c...          1\n",
              "42203  The Face on Mars is a fascinating phenomenon t...          1\n",
              "\n",
              "[127344 rows x 2 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop duplicates\n",
        "concat_eval_df.drop_duplicates(subset=[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dzdHsm4xkwIA"
      },
      "outputs": [],
      "source": [
        "sampled_eval_df, _ = train_test_split(concat_eval_df,\n",
        "                                       test_size=(len(concat_eval_df) - 20000) / len(concat_eval_df),\n",
        "                                       stratify=concat_eval_df[\"generated\"],\n",
        "                                       random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "p_ePdM7hlJNU"
      },
      "outputs": [],
      "source": [
        "sampled_eval_df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7AMrspwFlYu5"
      },
      "outputs": [],
      "source": [
        "val_df, test_df = train_test_split(sampled_eval_df,\n",
        "                                test_size=0.5,\n",
        "                                stratify=sampled_eval_df[\"generated\"],\n",
        "                                random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmwOL9Lcl9DM"
      },
      "source": [
        "# Preprocess text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_sentpiece_df = pd.concat([test_df[\"text\"], concat_train_df[\"text\"]])\n",
        "train_sentpiece_df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wy8LqVQxmAG5"
      },
      "outputs": [],
      "source": [
        "# Train sentence piece model\n",
        "\n",
        "import sentencepiece as spm\n",
        " \n",
        "# Write text data to a text file for SentencePiece training\n",
        "with open('sentpiece_train.txt', 'w', encoding='utf-8') as file:\n",
        "    for text in train_sentpiece_df:\n",
        "        file.write(text + '\\n')\n",
        "\n",
        "# Train SentencePiece model\n",
        "spm.SentencePieceTrainer.train(input='data/sentpiece_train.txt', model_prefix='data/sentpiece_model', vocab_size=30522)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "w82a1P57YATb"
      },
      "outputs": [],
      "source": [
        "def get_tokenized_text(df, tok_model_path):\n",
        "  sp = spm.SentencePieceProcessor()\n",
        "  sp.Load(tok_model_path)\n",
        "  # Tokenize text using SentencePiece\n",
        "  df['tokens'] = df['text'].apply(lambda x: sp.EncodeAsPieces(x.lower()))\n",
        "  # Convert SentencePiece tokens to text for XGBoost\n",
        "  df['text_spm'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "i0buINddZkD7"
      },
      "outputs": [],
      "source": [
        "#tokenized_train_one_df = get_tokenized_text(train_set_one, \"sentpiece_model.model\")\n",
        "#tokenized_train_two_df = get_tokenized_text(train_set_two, \"sentpiece_model.model\")\n",
        "#tokenized_train_three_df = get_tokenized_text(train_set_three, \"sentpiece_model.model\")\n",
        "tokenized_eval_df = get_tokenized_text(val_df, \"data/sentpiece_model.model\")\n",
        "tokenized_test_df = get_tokenized_text(test_df, \"data/sentpiece_model.model\")\n",
        "tokenized_main_train_df = get_tokenized_text(sampled_train_df, \"data/sentpiece_model.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Zh0Invy2Z6ew"
      },
      "outputs": [],
      "source": [
        "# X_train, X_val, y_train, y_val = train_test_split(df['text_spm'], df['generated'], test_size=0.2, random_state=42)\n",
        "vectorizer = TfidfVectorizer(ngram_range=(3, 5), \n",
        "                             sublinear_tf=True,\n",
        "                             lowercase=False,\n",
        "                             max_features=5000)\n",
        "\n",
        "#X_train_one = vectorizer.fit_transform(tokenized_train_one_df[\"text_spm\"])\n",
        "#X_train_two = vectorizer.transform(tokenized_train_two_df[\"text_spm\"])\n",
        "#X_train_three = vectorizer.transform(tokenized_train_three_df[\"text_spm\"])\n",
        "X_train_main = vectorizer.fit_transform(tokenized_main_train_df[\"text_spm\"])\n",
        "y_train_main = tokenized_main_train_df[\"generated\"]\n",
        "X_val = vectorizer.transform(tokenized_eval_df[\"text_spm\"])\n",
        "y_val = tokenized_eval_df[\"generated\"]\n",
        "X_test = vectorizer.transform(tokenized_eval_df[\"text_spm\"])\n",
        "y_test = tokenized_test_df[\"generated\"]\n",
        "#y_train_one = tokenized_train_one_df[\"generated\"]\n",
        "#y_train_two = tokenized_train_two_df[\"generated\"]\n",
        "#y_train_three = tokenized_train_three_df[\"generated\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the vectorizer\n",
        "joblib.dump(vectorizer, \"data/vectorizer.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_EH4EmCfMyD"
      },
      "source": [
        "# Modelling\n",
        "\n",
        "## Modelling with LGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Hyperparameter tune LGBM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [56:54<00:00, 68.29s/trial, best loss: -0.959269926304359]  \n",
            "Best Hyperparameters: {'colsample_bynode': 0.891492853612568, 'colsample_bytree': 0.8652279279632024, 'lambda_l1': 0.1497981206936176, 'lambda_l2': 2.5379309743954743, 'learning_rate': 0.04665576114608101, 'max_bin': 984.0, 'max_depth': 14.0, 'min_data_in_leaf': 50.0}\n"
          ]
        }
      ],
      "source": [
        "X_train_hyper, _, y_train_hyper, _ = train_test_split(X_train_main, y_train_main, train_size=0.1, random_state=42)\n",
        "\n",
        "def custom_metric(y_true, y_pred):\n",
        "    # Your custom metric, for example, a combination of ROC-AUC and recall for class 1\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "    recall_class_1 = recall_score(y_true, (y_pred > 0.5).astype(int), pos_label=1)\n",
        "\n",
        "    # You can adjust the weights based on your preference\n",
        "    custom_metric_value = 0.5 * roc_auc + 0.5 * recall_class_1\n",
        "    \n",
        "    return custom_metric_value\n",
        "\n",
        "def custom_metric_for_lgbm(y_true, y_pred):\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "    recall_class_1 = recall_score(y_true, (y_pred > 0.5).astype(int), pos_label=1)\n",
        "    custom_metric_value = 0.5 * roc_auc + 0.5 * recall_class_1\n",
        "    return 'custom', custom_metric_value, True\n",
        "\n",
        "custom_scorer = make_scorer(custom_metric, needs_proba=True)\n",
        "\n",
        "def objective(params):\n",
        "    params['objective'] = 'cross_entropy'\n",
        "    params['metric'] = 'custom'\n",
        "    params['n_iter'] = 2500\n",
        "    params['verbose'] = -1\n",
        "    params['min_data_in_leaf'] = int(params['min_data_in_leaf'])\n",
        "    params['max_depth'] = int(params['max_depth'])\n",
        "    params['max_bin'] = int(params['max_bin'])\n",
        "    \n",
        "\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    model = LGBMClassifier(**params)\n",
        "\n",
        "    scores = cross_val_score(estimator=model, X=X_train_hyper, y=y_train_hyper, cv=cv, scoring=custom_scorer, n_jobs=-1)\n",
        "\n",
        "    # Take the mean of the custom metric across folds\n",
        "    mean_score = np.mean(scores)\n",
        "\n",
        "    return -mean_score\n",
        "# Define the search space\n",
        "space = {\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.1),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.7, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.7, 1.0),\n",
        "    'lambda_l1': hp.uniform('lambda_l1', 0.1, 10),\n",
        "    'lambda_l2': hp.uniform('lambda_l2', 0.1, 10),\n",
        "    'min_data_in_leaf': hp.quniform('min_data_in_leaf', 50, 150, 1),\n",
        "    'max_depth': hp.quniform('max_depth', 10, 30, 1),\n",
        "    'max_bin': hp.quniform('max_bin', 500, 1000, 1),\n",
        "}\n",
        "\n",
        "# Run Hyperopt optimization\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=50, trials=trials, verbose=1)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "params = {'colsample_bynode': 0.891492853612568,\n",
        "          'colsample_bytree': 0.8652279279632024,\n",
        "          'lambda_l1': 0.1497981206936176,\n",
        "          'lambda_l2': 2.5379309743954743,\n",
        "          'learning_rate': 0.04665576114608101,\n",
        "          'max_bin': 984,\n",
        "          'max_depth': 14, \n",
        "          'min_data_in_leaf': 50,\n",
        "          'objective' : 'cross_entropy',\n",
        "          'metric' : 'auc',\n",
        "          'n_iter' : 2500,\n",
        "          'verbose' : -1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "lgbm = LGBMClassifier(**params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Spectra\\anaconda3\\Lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The ROC: 0.998834454466469\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      6888\n",
            "           1       0.99      0.98      0.98      3112\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lgbm.fit(X_train_main, y_train_main)\n",
        "y_pred_proba = lgbm.predict_proba(X_val)[:, 1]\n",
        "y_pred = lgbm.predict(X_val)\n",
        "roc = roc_auc_score(y_val, y_pred_proba)\n",
        "\n",
        "print(\"The ROC:\", roc)\n",
        "print(classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<lightgbm.basic.Booster at 0x167e2dd04d0>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lgbm.booster_.save_model('lgbm_model.txt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
